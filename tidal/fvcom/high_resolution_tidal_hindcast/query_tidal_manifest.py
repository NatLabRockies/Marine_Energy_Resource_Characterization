"""
Query library for tidal parquet partition manifests

This module provides efficient spatial queries against the ultra-compact grid centroid
manifests generated by generate_parquet_partition_manifest_json.py.

Features:
- KDTree-based spatial indexing for fast nearest-neighbor queries
- Support for manifest spec with versioning and self-documenting schema
- Path reconstruction for direct parquet file access
- Version resolution (latest version per location, or specific version)
- S3 cache integration for on-demand grid file loading

Uses scipy.spatial.cKDTree for fast nearest-neighbor spatial indexing.
"""

import json
import re
from pathlib import Path
from typing import List, Tuple, Optional, Dict, Any
import numpy as np
from scipy.spatial import cKDTree


class TidalManifestQuery:
    """
    Query interface for tidal parquet partition manifests.

    Provides spatial query methods:
    - query_nearest_point: Find nearest grid to a point
    - query_all_within_rectangular_area: Find all grids in bounding box
    - query_all_on_line: Find grids along a line
    """

    @staticmethod
    def haversine_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> float:
        """
        Calculate the great circle distance between two points on Earth using haversine formula.

        Parameters
        ----------
        lat1, lon1 : float
            Latitude and longitude of first point in decimal degrees
        lat2, lon2 : float
            Latitude and longitude of second point in decimal degrees

        Returns
        -------
        float
            Distance in kilometers

        Notes
        -----
        Uses mean Earth radius of 6371 km.
        """
        # Convert to radians
        lat1_rad = np.radians(lat1)
        lat2_rad = np.radians(lat2)
        lon1_rad = np.radians(lon1)
        lon2_rad = np.radians(lon2)

        # Haversine formula
        dlat = lat2_rad - lat1_rad
        dlon = lon2_rad - lon1_rad

        a = (
            np.sin(dlat / 2) ** 2
            + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2) ** 2
        )
        c = 2 * np.arcsin(np.sqrt(a))

        # Earth radius in kilometers
        r = 6371.0

        return r * c

    @staticmethod
    def parse_wkt_polygon(wkt_string: str) -> List[List[float]]:
        """
        Parse WKT POLYGON string to list of coordinate pairs.

        Parameters
        ----------
        wkt_string : str
            WKT POLYGON string, e.g., "POLYGON ((lon1 lat1, lon2 lat2, ...))"

        Returns
        -------
        list of list of float
            List of [lon, lat] coordinate pairs in GeoJSON order

        Examples
        --------
        >>> wkt = "POLYGON ((-175.0 49.9, -174.9 49.9, -174.9 50.0, -175.0 50.0, -175.0 49.9))"
        >>> coords = TidalManifestQuery.parse_wkt_polygon(wkt)
        >>> len(coords)
        5
        """
        # Extract coordinate string from POLYGON ((...))
        match = re.search(r"POLYGON\s*\(\(([^)]+)\)\)", wkt_string)
        if not match:
            raise ValueError(f"Invalid WKT POLYGON format: {wkt_string}")

        coord_string = match.group(1)

        # Parse coordinate pairs
        coords = []
        for pair in coord_string.split(","):
            parts = pair.strip().split()
            if len(parts) != 2:
                raise ValueError(f"Invalid coordinate pair: {pair}")
            lon, lat = float(parts[0]), float(parts[1])
            coords.append([lon, lat])

        return coords

    def __init__(self, manifest_path: Path, s3_cache=None):
        """
        Initialize query interface by loading manifest and building KDTree.

        Parameters
        ----------
        manifest_path : Path
            Path to manifest_{version}.json file (spec v2.0.0 format)
        s3_cache : S3CacheManager, optional
            S3 cache manager for fetching grid files on-demand from S3.
            If provided, grid files will be fetched from S3 when not available locally.
            Required when manifest is downloaded from S3.
        """
        self.manifest_path = Path(manifest_path)
        self.manifest_dir = self.manifest_path.parent
        self.grids_dir = self.manifest_dir / "grids"
        self.s3_cache = s3_cache

        # Load manifest
        with open(self.manifest_path, "r") as f:
            self.manifest = json.load(f)

        # Validate manifest format (spec v2.0.0 required)
        if "spec_version" not in self.manifest:
            raise ValueError(
                "Invalid manifest format: missing 'spec_version'. "
                "This query interface requires spec v2.0.0 or later."
            )

        # Extract versioning info
        self.spec_version = self.manifest["spec_version"]
        self.manifest_version = self.manifest["manifest_version"]

        # Extract dataset info
        self.dataset = self.manifest["dataset"]

        # Extract partition configuration
        partition = self.manifest["partition"]
        self.decimal_places = partition["decimal_places"]
        self.grid_resolution_deg = partition["grid_resolution_deg"]
        self.data_level = partition["data_level"]
        self.coord_digits_max = partition["coord_digits_max"]
        self.index_max_digits = partition["index_max_digits"]

        # Extract path template and storage configuration
        self.path_template = self.manifest["path_template"]["template"]
        self.storage = self.manifest["storage"]

        # Extract summary stats
        self.total_grids = self.manifest["total_grids"]
        self.total_points = self.manifest["total_points"]

        # Extract grid centroids
        self.grid_lats = np.array(self.manifest["grid_centroids"]["lat"])
        self.grid_lons = np.array(self.manifest["grid_centroids"]["lon"])

        # Build KDTree for fast spatial queries
        self.grid_coords = np.column_stack([self.grid_lats, self.grid_lons])
        self.kdtree = cKDTree(self.grid_coords)

        print(
            f"Loaded manifest (spec v{self.spec_version}, manifest v{self.manifest_version})"
        )
        print(f"  Dataset: {self.dataset['label']}")
        print(f"  Total grids: {self.total_grids:,}")
        print(f"  Total points: {self.total_points:,}")
        print(f"  Grid resolution: {self.grid_resolution_deg}°")
        print(f"  Locations: {list(self.manifest['locations'].keys())}")
        print(f"  S3 base: {self.storage['s3_base_uri']}")

    def _centroid_to_grid_id(self, centroid_lat: float, centroid_lon: float) -> str:
        """
        Calculate grid ID from centroid coordinates.

        Reverse engineers the grid ID from the centroid by:
        1. Calculating corner coordinates (centroid - grid_res/2)
        2. Extracting integer and decimal components

        Parameters
        ----------
        centroid_lat : float
            Grid centroid latitude
        centroid_lon : float
            Grid centroid longitude

        Returns
        -------
        str
            Grid ID in format "lat_deg_lon_deg_lat_dec_lon_dec"
        """
        grid_res = self.grid_resolution_deg

        # Calculate top-left corner from centroid
        corner_lat = centroid_lat - grid_res / 2
        corner_lon = centroid_lon - grid_res / 2

        # Extract integer and decimal parts
        # IMPORTANT: Must match the encoding in vap_simple_create_parquet_all_time_partition.py:
        #   lat_deg = int(lat)
        #   lat_dec = int(abs(lat * 100) % 100)
        # Example: corner_lon=-70.70 gives lon_deg=-70 (not -71!), lon_dec=70
        # Reconstruction: -70 - 0.70 = -70.70 (for negative coords, we subtract dec)
        lat_deg = int(corner_lat)
        lat_dec = int(
            round(
                abs(corner_lat * (10**self.decimal_places)) % (10**self.decimal_places)
            )
        )

        lon_deg = int(corner_lon)
        lon_dec = int(
            round(
                abs(corner_lon * (10**self.decimal_places)) % (10**self.decimal_places)
            )
        )

        return f"{lat_deg}_{lon_deg}_{lat_dec}_{lon_dec}"

    def _load_grid_details(self, grid_id: str) -> Dict[str, Any]:
        """
        Load detailed grid information from grids/ subdirectory.

        Grid files are organized in nested directories:
        grids/lat_{lat_deg}/lon_{lon_deg}/{grid_id}.json

        If an S3 cache manager is configured, grid files will be fetched
        from S3 on-demand when not available locally.

        New compact format:
        {
            "grid_id": "61_-149_46_63",
            "points_columns": ["lat", "lon", "face_id"],
            "points": [["61.4657288", "-149.6356201", "002499"], ...]
        }

        Parameters
        ----------
        grid_id : str
            Grid identifier in format "lat_deg_lon_deg_lat_dec_lon_dec"

        Returns
        -------
        dict
            Grid details with compact point arrays
        """
        # Parse grid_id to extract lat_deg and lon_deg
        # Format: "lat_deg_lon_deg_lat_dec_lon_dec"
        parts = grid_id.split("_")
        lat_deg = parts[0]
        lon_deg = parts[1]

        # Construct relative path to nested grid file
        relative_grid_path = f"manifest/v{self.manifest_version}/grids/lat_{lat_deg}/lon_{lon_deg}/{grid_id}.json"

        # Try local grids_dir first
        grid_file = (
            self.grids_dir / f"lat_{lat_deg}" / f"lon_{lon_deg}" / f"{grid_id}.json"
        )

        if grid_file.exists():
            with open(grid_file, "r") as f:
                return json.load(f)

        # If not found locally and we have S3 cache, fetch from S3
        if self.s3_cache is not None:
            return self.s3_cache.get_json(relative_grid_path, validate=False)

        raise FileNotFoundError(f"Grid detail file not found: {grid_file}")

    def reconstruct_path(
        self,
        point: List[str],
        location_name: str,
        version: Optional[str] = None,
    ) -> str:
        """
        Reconstruct full parquet file path from point data.

        Uses the path_template and location metadata from the manifest
        to rebuild the exact file path.

        Parameters
        ----------
        point : list of str
            Point data as [lat_str, lon_str, face_id_str]
        location_name : str
            Location identifier (e.g., "AK_cook_inlet")
        version : str, optional
            Data version to use. If None, uses the location's latest_version.

        Returns
        -------
        str
            Full path to parquet file (relative to S3 base URI)

        Examples
        --------
        >>> point = ["61.4657288", "-149.6356201", "002499"]
        >>> path = query.reconstruct_path(point, "AK_cook_inlet")
        >>> print(path)
        AK_cook_inlet/1.0.0/b1_vap_by_point_partition/lat_deg=61/lon_deg=-149/lat_dec=46/lon_dec=63/AK_cook_inlet.wpto_high_res_tidal.face=002499.lat=61.4657288.lon=-149.6356201-1h.b4.20050101.000000.parquet
        """
        lat_str, lon_str, face_id_str = point
        lat = float(lat_str)
        lon = float(lon_str)

        # Calculate partition components using decimal_places from manifest
        multiplier = 10**self.decimal_places
        lat_deg = int(lat)
        lon_deg = int(lon)
        lat_dec = int(abs(lat * multiplier) % multiplier)
        lon_dec = int(abs(lon * multiplier) % multiplier)

        # Get location-specific metadata
        if location_name not in self.manifest["locations"]:
            raise ValueError(f"Unknown location: {location_name}")

        loc_meta = self.manifest["locations"][location_name]

        # Resolve version - use provided version or location's latest_version
        if version is None:
            version = loc_meta.get("latest_version", "1.0.0")

        # Pad face_id to index_max_digits (e.g., "125685" -> "00125685")
        face_id_padded = face_id_str.zfill(self.index_max_digits)

        # Substitute into path template
        path = self.path_template.format(
            location=location_name,
            data_version=version,
            data_level=self.data_level,
            lat_deg=lat_deg,
            lon_deg=lon_deg,
            lat_dec=lat_dec,
            lon_dec=lon_dec,
            face_id=face_id_padded,  # Zero-padded to index_max_digits
            lat=lat_str,  # Use string directly (preserves precision)
            lon=lon_str,  # Use string directly (preserves precision)
            temporal=loc_meta["temporal"],
            date=loc_meta["date"],
            time=loc_meta["time"],
        )

        return path

    def get_s3_uri(self, relative_path: str) -> str:
        """
        Convert a relative path to a full S3 URI.

        Parameters
        ----------
        relative_path : str
            Relative path from reconstruct_path()

        Returns
        -------
        str
            Full S3 URI (e.g., s3://marine-energy-data/us-tidal/AK_cook_inlet/...)
        """
        if not self.storage:
            raise ValueError("Manifest does not contain storage configuration")
        return f"{self.storage['s3_base_uri']}/{relative_path}"

    def get_hpc_path(self, relative_path: str) -> str:
        """
        Convert a relative path to a full HPC filesystem path.

        Use this when running on NREL's Kestrel HPC system to access
        data files directly from the local filesystem.

        Parameters
        ----------
        relative_path : str
            Relative path from reconstruct_path()

        Returns
        -------
        str
            Full HPC filesystem path (e.g., /projects/hindcastra/Tidal/datasets/...)
        """
        if not self.storage.get("hpc_base_path"):
            raise ValueError("Manifest does not contain HPC base path configuration")
        return f"{self.storage['hpc_base_path']}/{relative_path}"

    def get_full_path(self, relative_path: str, use_hpc: bool = False) -> str:
        """
        Convert a relative path to a full path (S3 or HPC).

        This is a convenience method that switches between S3 and HPC paths
        based on the use_hpc flag.

        Parameters
        ----------
        relative_path : str
            Relative path from reconstruct_path()
        use_hpc : bool, default False
            If True, return HPC filesystem path.
            If False, return S3 URI.

        Returns
        -------
        str
            Full path (S3 URI or HPC filesystem path)

        Examples
        --------
        >>> # For S3 access (default)
        >>> path = query.get_full_path(relative_path)
        s3://marine-energy-data/us-tidal/AK_cook_inlet/...

        >>> # For HPC local access
        >>> path = query.get_full_path(relative_path, use_hpc=True)
        /projects/hindcastra/Tidal/datasets/high_resolution_tidal_hindcast/AK_cook_inlet/...
        """
        if use_hpc:
            return self.get_hpc_path(relative_path)
        return self.get_s3_uri(relative_path)

    def get_location_version_info(self, location_name: str) -> Dict[str, Any]:
        """
        Get version information for a specific location.

        Parameters
        ----------
        location_name : str
            Location identifier (e.g., "AK_cook_inlet")

        Returns
        -------
        dict
            Dictionary with keys:
            - latest_version: The recommended/latest version
            - versions: Dict mapping version strings to metadata (release_date, etc.)

        Examples
        --------
        >>> info = query.get_location_version_info("AK_cook_inlet")
        >>> print(info["latest_version"])
        1.0.0
        >>> print(info["versions"]["1.0.0"]["release_date"])
        2025-11-12
        """
        if location_name not in self.manifest["locations"]:
            raise ValueError(f"Unknown location: {location_name}")

        loc_meta = self.manifest["locations"][location_name]
        return {
            "latest_version": loc_meta.get("latest_version", "unknown"),
            "versions": loc_meta.get("versions", {}),
        }

    def query_nearest_point(
        self,
        lat: float,
        lon: float,
        max_distance_deg: Optional[float] = None,
        load_details: bool = True,
    ) -> Dict[str, Any]:
        """
        Find nearest data point to a given location.

        Searches neighboring grids to ensure the truly closest point is found,
        since the nearest point may be in an adjacent grid.

        Parameters
        ----------
        lat : float
            Query latitude
        lon : float
            Query longitude
        max_distance_deg : float, optional
            Maximum distance threshold in degrees. If specified, returns None
            if nearest point is farther than this distance.
        load_details : bool, default=True
            Whether to load full grid details.

        Returns
        -------
        dict or None
            Result dictionary with keys:
            - point: dict with face, lat, lon, file_path
            - distance_km: great circle distance from query to point in kilometers (haversine)
            - grid_id: grid identifier containing the point
            - details: grid details (if load_details=True)

            Returns None if no points found or max_distance_deg is exceeded.

        Examples
        --------
        >>> query = TidalManifestQuery(Path("manifests/v0.3.0/manifest.json"))
        >>> result = query.query_nearest_point(lat=49.94, lon=-174.96)
        >>> print(result['point']['face'])
        23497
        >>> print(result['distance_km'])
        0.50
        """
        # Search multiple nearby grids (use 3x grid resolution to capture neighbors)
        search_radius = 3 * self.grid_resolution_deg

        # Get all grids within search radius using KDTree
        # Use query_ball_point to get ALL grids within radius (not just k nearest)
        query_point = np.array([lat, lon])
        valid_indices = self.kdtree.query_ball_point(query_point, r=search_radius)

        if len(valid_indices) == 0:
            return None

        # Search all nearby grids for the closest point using haversine distance
        min_distance_km = float("inf")
        closest_point_array = None
        closest_location = None
        closest_grid_id = None
        closest_details = None

        for idx in valid_indices:
            centroid_lat = self.grid_lats[idx]
            centroid_lon = self.grid_lons[idx]
            grid_id = self._centroid_to_grid_id(centroid_lat, centroid_lon)

            try:
                details = self._load_grid_details(grid_id)
                location_name = details["location"]

                # Check all points in this grid
                # New format: points = [["lat_str", "lon_str", "face_id_str"], ...]
                for point_array in details["points"]:
                    lat_str, lon_str, face_id_str = point_array
                    point_lat = float(lat_str)
                    point_lon = float(lon_str)

                    # Calculate proper haversine distance
                    distance_km = self.haversine_distance(
                        lat, lon, point_lat, point_lon
                    )

                    if distance_km < min_distance_km:
                        min_distance_km = distance_km
                        closest_point_array = point_array
                        closest_location = location_name
                        closest_grid_id = grid_id
                        closest_details = details

            except FileNotFoundError:
                continue

        # Check distance threshold (convert to km if specified in degrees)
        if max_distance_deg is not None:
            # Convert degree threshold to km using approximate conversion
            max_distance_km = max_distance_deg * 111.0
            if min_distance_km > max_distance_km:
                return None

        if closest_point_array is None:
            return None

        # Parse point array to create structured result
        lat_str, lon_str, face_id_str = closest_point_array

        # Reconstruct file path
        file_path = self.reconstruct_path(closest_point_array, closest_location)

        result = {
            "point": {
                "face_id": face_id_str,
                "lat": float(lat_str),
                "lon": float(lon_str),
                "file_path": file_path,
            },
            "distance_km": float(min_distance_km),
            "location": closest_location,
            "grid_id": closest_grid_id,
        }

        if load_details:
            result["details"] = closest_details

        return result

    def query_all_within_rectangular_area(
        self,
        lat_min: float,
        lat_max: float,
        lon_min: float,
        lon_max: float,
        max_distance_deg: Optional[float] = None,
        load_details: bool = True,
    ) -> List[Dict[str, Any]]:
        """
        Find all grids within a rectangular bounding box.

        Parameters
        ----------
        lat_min : float
            Minimum latitude
        lat_max : float
            Maximum latitude
        lon_min : float
            Minimum longitude
        lon_max : float
            Maximum longitude
        max_distance_deg : float, optional
            Additional buffer distance in degrees. If specified, includes grids
            within this distance of the bounding box edges.
        load_details : bool, default=True
            Whether to load full grid details for each result.

        Returns
        -------
        list of dict
            List of result dictionaries, each with keys:
            - centroid: (lat, lon) tuple
            - grid_id: grid identifier
            - details: grid details (if load_details=True)

        Examples
        --------
        >>> query = TidalManifestQuery(Path("manifests/v0.3.0/manifest.json"))
        >>> results = query.query_all_within_rectangular_area(
        ...     lat_min=49.9, lat_max=50.0,
        ...     lon_min=-175.0, lon_max=-174.9
        ... )
        >>> print(f"Found {len(results)} grids")
        Found 12 grids
        """
        # Simple bounding box filter
        if max_distance_deg is None:
            # No buffer - direct bounding box
            mask = (
                (self.grid_lats >= lat_min)
                & (self.grid_lats <= lat_max)
                & (self.grid_lons >= lon_min)
                & (self.grid_lons <= lon_max)
            )
            indices = np.where(mask)[0]
        else:
            # Use KDTree query with buffer distance
            # Query all points within max_distance of bounding box
            # Create test points along bounding box perimeter
            n_test = 100  # Number of test points per edge

            # Top and bottom edges
            top_edge = np.column_stack(
                [np.full(n_test, lat_max), np.linspace(lon_min, lon_max, n_test)]
            )
            bottom_edge = np.column_stack(
                [np.full(n_test, lat_min), np.linspace(lon_min, lon_max, n_test)]
            )

            # Left and right edges
            left_edge = np.column_stack(
                [np.linspace(lat_min, lat_max, n_test), np.full(n_test, lon_min)]
            )
            right_edge = np.column_stack(
                [np.linspace(lat_min, lat_max, n_test), np.full(n_test, lon_max)]
            )

            # Combine all edge points
            edge_points = np.vstack([top_edge, bottom_edge, left_edge, right_edge])

            # Query KDTree for all points within max_distance of edges
            indices_list = self.kdtree.query_ball_point(edge_points, r=max_distance_deg)

            # Flatten and get unique indices
            indices = np.unique(np.concatenate(indices_list))

        # Build results
        results = []
        for idx in indices:
            centroid_lat = self.grid_lats[idx]
            centroid_lon = self.grid_lons[idx]
            grid_id = self._centroid_to_grid_id(centroid_lat, centroid_lon)

            result = {
                "centroid": (float(centroid_lat), float(centroid_lon)),
                "grid_id": grid_id,
            }

            if load_details:
                result["details"] = self._load_grid_details(grid_id)

            results.append(result)

        return results

    def query_all_on_line(
        self,
        start_lat: float,
        start_lon: float,
        end_lat: float,
        end_lon: float,
        max_distance_deg: float = 0.1,
        max_points: Optional[int] = None,
        load_details: bool = True,
    ) -> List[Dict[str, Any]]:
        """
        Find all grids along a line segment.

        Parameters
        ----------
        start_lat : float
            Starting latitude
        start_lon : float
            Starting longitude
        end_lat : float
            Ending latitude
        end_lon : float
            Ending longitude
        max_distance_deg : float, default=0.1
            Maximum perpendicular distance from line in degrees.
            Only grids within this distance of the line are included.
        max_points : int, optional
            Maximum number of points to return. If specified, returns the
            closest max_points grids to the line, sorted by distance.
        load_details : bool, default=True
            Whether to load full grid details for each result.

        Returns
        -------
        list of dict
            List of result dictionaries, each with keys:
            - centroid: (lat, lon) tuple
            - grid_id: grid identifier
            - distance_from_line_deg: perpendicular distance from line
            - distance_along_line_deg: distance along line from start point
            - details: grid details (if load_details=True)

            Sorted by distance_along_line_deg.

        Examples
        --------
        >>> query = TidalManifestQuery(Path("manifests/v0.3.0/manifest.json"))
        >>> results = query.query_all_on_line(
        ...     start_lat=49.9, start_lon=-175.0,
        ...     end_lat=50.0, end_lon=-174.9,
        ...     max_distance_deg=0.05
        ... )
        >>> for r in results[:5]:
        ...     print(f"Grid {r['grid_id']}: {r['distance_along_line_deg']:.4f}° along line")
        """
        # Calculate line parameters
        line_start = np.array([start_lat, start_lon])
        line_end = np.array([end_lat, end_lon])
        line_vec = line_end - line_start
        line_length = np.linalg.norm(line_vec)
        line_unit = line_vec / line_length

        # Calculate perpendicular distance for all grid centroids
        # Vector from line start to each centroid
        centroid_vecs = self.grid_coords - line_start

        # Project onto line direction
        distances_along = np.dot(centroid_vecs, line_unit)

        # Calculate perpendicular component
        projections = np.outer(distances_along, line_unit)
        perpendicular_vecs = centroid_vecs - projections
        distances_perp = np.linalg.norm(perpendicular_vecs, axis=1)

        # Filter by perpendicular distance
        mask = distances_perp <= max_distance_deg

        # Also filter to points between start and end (with some buffer)
        mask &= (distances_along >= -max_distance_deg) & (
            distances_along <= line_length + max_distance_deg
        )

        indices = np.where(mask)[0]

        if len(indices) == 0:
            return []

        # Build results with distance information
        results = []
        for idx in indices:
            centroid_lat = self.grid_lats[idx]
            centroid_lon = self.grid_lons[idx]
            grid_id = self._centroid_to_grid_id(centroid_lat, centroid_lon)

            result = {
                "centroid": (float(centroid_lat), float(centroid_lon)),
                "grid_id": grid_id,
                "distance_from_line_deg": float(distances_perp[idx]),
                "distance_along_line_deg": float(distances_along[idx]),
            }

            if load_details:
                result["details"] = self._load_grid_details(grid_id)

            results.append(result)

        # Sort by distance along line
        results.sort(key=lambda x: x["distance_along_line_deg"])

        # Limit to max_points if specified
        if max_points is not None:
            # Sort by perpendicular distance to get closest points
            results_sorted_by_distance = sorted(
                results, key=lambda x: x["distance_from_line_deg"]
            )
            results = results_sorted_by_distance[:max_points]
            # Re-sort by distance along line
            results.sort(key=lambda x: x["distance_along_line_deg"])

        return results

    def generate_grid_boundaries_geojson(
        self, aggregation_deg: Optional[float] = None
    ) -> Dict[str, Any]:
        """
        Generate GeoJSON FeatureCollection of grid boundaries.

        Can generate either individual grid cells or aggregated regions.

        Parameters
        ----------
        aggregation_deg : float, optional
            If specified, groups grids into coarser regions (e.g., 0.1° boxes).
            If None (default), generates individual grid cells for all grids.

        Returns
        -------
        dict
            GeoJSON FeatureCollection with grid boundary polygons.

        Examples
        --------
        >>> query = TidalManifestQuery(Path("manifests/v0.3.0/manifest.json"))
        >>> # All individual grids
        >>> geojson = query.generate_grid_boundaries_geojson()
        >>> # Aggregated grids
        >>> geojson = query.generate_grid_boundaries_geojson(aggregation_deg=0.1)
        """
        half_grid = self.grid_resolution_deg / 2

        if aggregation_deg is None:
            # Generate individual grid cells for all grids (fully vectorized)
            print(f"Generating {self.total_grids:,} individual grid boundaries...")

            # Vectorized calculation of all grid corners
            lat_mins = self.grid_lats - half_grid
            lat_maxs = self.grid_lats + half_grid
            lon_mins = self.grid_lons - half_grid
            lon_maxs = self.grid_lons + half_grid

            # Build all features using list comprehension (Python-level vectorization)
            features = [
                {
                    "type": "Feature",
                    "geometry": {
                        "type": "Polygon",
                        "coordinates": [
                            [
                                [float(lon_mins[i]), float(lat_mins[i])],
                                [float(lon_maxs[i]), float(lat_mins[i])],
                                [float(lon_maxs[i]), float(lat_maxs[i])],
                                [float(lon_mins[i]), float(lat_maxs[i])],
                                [float(lon_mins[i]), float(lat_mins[i])],
                            ]
                        ],
                    },
                    "properties": {},
                }
                for i in range(len(self.grid_lats))
            ]

            print(f"Generated {len(features):,} grid boundaries")

        else:
            # Aggregated mode (fully vectorized)
            print(f"Aggregating grids into {aggregation_deg}° regions...")

            # Bin grids into aggregation boxes (vectorized)
            box_lats = np.floor(self.grid_lats / aggregation_deg) * aggregation_deg
            box_lons = np.floor(self.grid_lons / aggregation_deg) * aggregation_deg

            # Create unique box identifiers
            box_keys = np.column_stack([box_lats, box_lons])
            unique_boxes, inverse_indices, counts = np.unique(
                box_keys, axis=0, return_inverse=True, return_counts=True
            )

            # Vectorized bounds calculation for all unique boxes
            # Use pandas groupby for vectorized min/max operations
            import pandas as pd

            df = pd.DataFrame(
                {
                    "lat": self.grid_lats,
                    "lon": self.grid_lons,
                    "box_idx": inverse_indices,
                }
            )

            grouped = df.groupby("box_idx").agg(
                {"lat": ["min", "max"], "lon": ["min", "max"]}
            )

            lat_mins_agg = grouped["lat"]["min"].values - half_grid
            lat_maxs_agg = grouped["lat"]["max"].values + half_grid
            lon_mins_agg = grouped["lon"]["min"].values - half_grid
            lon_maxs_agg = grouped["lon"]["max"].values + half_grid

            # Build all features using list comprehension
            features = [
                {
                    "type": "Feature",
                    "geometry": {
                        "type": "Polygon",
                        "coordinates": [
                            [
                                [float(lon_mins_agg[i]), float(lat_mins_agg[i])],
                                [float(lon_maxs_agg[i]), float(lat_mins_agg[i])],
                                [float(lon_maxs_agg[i]), float(lat_maxs_agg[i])],
                                [float(lon_mins_agg[i]), float(lat_maxs_agg[i])],
                                [float(lon_mins_agg[i]), float(lat_mins_agg[i])],
                            ]
                        ],
                    },
                    "properties": {"grid_count": int(counts[i])},
                }
                for i in range(len(unique_boxes))
            ]

            print(
                f"Aggregated {self.total_grids:,} grids into {len(features):,} regions"
            )

        geojson = {"type": "FeatureCollection", "features": features}

        return geojson

    def generate_location_boundaries_geojson(self) -> Dict[str, Any]:
        """
        Generate GeoJSON FeatureCollection of location boundaries from manifest.

        Uses the geospatial_bounds (WKT POLYGON) from each location in the manifest.

        Returns
        -------
        dict
            GeoJSON FeatureCollection with location boundary polygons.
            Each feature has properties: location, label, point_count

        Examples
        --------
        >>> query = TidalManifestQuery(Path("manifests/v0.3.0/manifest.json"))
        >>> geojson = query.generate_location_boundaries_geojson()
        >>> print(f"Generated {len(geojson['features'])} location boundaries")
        """
        if "locations" not in self.manifest:
            raise ValueError(
                "Manifest does not contain 'locations' data. "
                "Please regenerate manifest with updated generate_parquet_partition_manifest_json.py"
            )

        locations = self.manifest["locations"]
        features = []

        for location_name, location_data in locations.items():
            # Check if geospatial_bounds exists
            if "geospatial_bounds" not in location_data:
                print(
                    f"Warning: Location '{location_name}' has no geospatial_bounds, skipping"
                )
                continue

            wkt_polygon = location_data["geospatial_bounds"]

            try:
                # Parse WKT POLYGON to coordinates
                coordinates = self.parse_wkt_polygon(wkt_polygon)

                # Create GeoJSON feature
                feature = {
                    "type": "Feature",
                    "geometry": {"type": "Polygon", "coordinates": [coordinates]},
                    "properties": {
                        "location": location_name,
                        "label": location_data.get("label", location_name),
                        "point_count": location_data.get("point_count", 0),
                    },
                }

                features.append(feature)

            except ValueError as e:
                print(
                    f"Warning: Could not parse geospatial_bounds for location '{location_name}': {e}"
                )
                continue

        geojson = {"type": "FeatureCollection", "features": features}

        print(f"Generated {len(features)} location boundary polygons")

        return geojson


def main():
    """
    Example usage of TidalManifestQuery.
    """
    # Example manifest path (adjust for your environment)
    manifest_path = Path(
        "/projects/hindcastra/Tidal/datasets/high_resolution_tidal_hindcast/manifests/v0.3.0/manifest.json"
    )

    if not manifest_path.exists():
        print(f"Manifest not found at {manifest_path}")
        print(
            "Please update the path in the script or run generate_parquet_partition_manifest_json.py first."
        )
        return

    # Initialize query interface
    query = TidalManifestQuery(manifest_path)

    print("\n" + "=" * 80)
    print("Example 1: Query nearest point")
    print("=" * 80)

    result = query.query_nearest_point(lat=49.94, lon=-174.96, load_details=False)
    if result:
        print("Query point: (49.94, -174.96)")
        print(f"Nearest grid: {result['grid_id']}")
        print(f"Grid centroid: {result['centroid']}")
        print(f"Distance: {result['distance_deg']:.6f}°")

    print("\n" + "=" * 80)
    print("Example 2: Query rectangular area")
    print("=" * 80)

    results = query.query_all_within_rectangular_area(
        lat_min=49.9, lat_max=50.0, lon_min=-175.0, lon_max=-174.9, load_details=False
    )
    print("Bounding box: lat=[49.9, 50.0], lon=[-175.0, -174.9]")
    print(f"Found {len(results)} grids")
    if results:
        print("First 5 grids:")
        for r in results[:5]:
            print(f"  {r['grid_id']}: {r['centroid']}")

    print("\n" + "=" * 80)
    print("Example 3: Query along line")
    print("=" * 80)

    results = query.query_all_on_line(
        start_lat=49.9,
        start_lon=-175.0,
        end_lat=50.0,
        end_lon=-174.9,
        max_distance_deg=0.05,
        max_points=10,
        load_details=False,
    )
    print("Line: (49.9, -175.0) → (50.0, -174.9)")
    print("Max distance from line: 0.05°")
    print("Max points: 10")
    print(f"Found {len(results)} grids")
    if results:
        print("Grids along line:")
        for r in results:
            print(
                f"  {r['grid_id']}: {r['distance_along_line_deg']:.4f}° along, {r['distance_from_line_deg']:.4f}° perp"
            )


if __name__ == "__main__":
    main()
